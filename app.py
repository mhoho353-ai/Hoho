import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import joblib
import io
import base64
from PIL import Image
import streamlit.components.v1 as components
import warnings
warnings.filterwarnings('ignore')

# Data processing libraries
from ydata_profiling import ProfileReport
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler
import pycaret
from pycaret.regression import *
from pycaret.classification import *

# Custom CSS for professional look
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
    }
    .success-box {
        background-color: #d4edda;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #28a745;
    }
</style>
""", unsafe_allow_html=True)

# Page config
st.set_page_config(
    page_title="DataWizard Pro",
    page_icon="ğŸ§™â€â™‚ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Session state initialization
if 'df' not in st.session_state:
    st.session_state.df = None
if 'clean_df' not in st.session_state:
    st.session_state.clean_df = None
if 'models' not in st.session_state:
    st.session_state.models = {}
if 'scaler' not in st.session_state:
    st.session_state.scaler = None

class DataWizardPro:
    def __init__(self):
        self.progress = st.progress(0)
    
    def load_data(self):
        """Professional data loading with multiple formats"""
        st.markdown('<h1 class="main-header">ğŸ§™â€â™‚ï¸ DataWizard Pro</h1>', unsafe_allow_html=True)
        st.markdown("**Ù„ÙˆØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙƒØ§Ù…Ù„Ø© - ØªÙ†Ø¸ÙŠÙ | Ø§Ø³ØªÙƒØ´Ø§Ù | ØªØ­Ù„ÙŠÙ„ | ML | ØªØµÙˆØ±**")
        
        col1, col2 = st.columns([3,1])
        with col1:
            uploaded_file = st.file_uploader(
                "ğŸ“ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (CSV, Excel, JSON)",
                type=['csv', 'xlsx', 'xls', 'json'],
                help="ÙŠØ¯Ø¹Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„ØµÙŠØº Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©"
            )
        with col2:
            st.info("**Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©:**
âœ… ØªÙ†Ø¸ÙŠÙ ØªÙ„Ù‚Ø§Ø¦ÙŠ
âœ… AutoML
âœ… 25+ ØªØµÙˆØ±
âœ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")
        
        if uploaded_file:
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                elif uploaded_file.name.endswith(('.xlsx', '.xls')):
                    df = pd.read_excel(uploaded_file)
                elif uploaded_file.name.endswith('.json'):
                    df = pd.read_json(uploaded_file)
                
                st.session_state.df = df
                st.session_state.progress.progress(20)
                st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!
ğŸ“Š Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {df.shape[0]:,} ØµÙ Ã— {df.shape[1]} Ø¹Ù…ÙˆØ¯")
                st.dataframe(df.head(), use_container_width=True)
                return True
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù: {str(e)}")
        return False
    
    def auto_clean(self, df):
        """Advanced automated data cleaning"""
        st.markdown("### ğŸ§¹ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            drop_na = st.checkbox("ğŸ—‘ï¸ Ø­Ø°Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©", value=True)
        with col2:
            fill_strategy = st.selectbox("Ù…Ù„Ø¡ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©", 
                                       ["Ù…ØªÙˆØ³Ø·", "ÙˆØ³ÙŠØ·", "Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±", "Ø«Ø§Ø¨Øª"])
        with col3:
            drop_duplicates = st.checkbox("ğŸ“‹ Ø­Ø°Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª", value=True)
        with col4:
            outlier_method = st.selectbox("Ø§Ù„Ù…ØªØ·Ø±ÙØ§Øª", ["Ù„Ø§", "IQR", "Z-score"])
        
        df_clean = df.copy()
        
        # Missing values handling
        if drop_na:
            initial_na = df_clean.isnull().sum().sum()
            df_clean = df_clean.dropna()
            st.success(f"Ø­ÙØ°ÙØª {initial_na - df_clean.isnull().sum().sum():,} Ù‚ÙŠÙ…Ø© Ù…ÙÙ‚ÙˆØ¯Ø©")
        
        # Fill missing values
        numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
        if fill_strategy != "Ø«Ø§Ø¨Øª" and len(numeric_cols) > 0:
            for col in numeric_cols:
                if df_clean[col].isnull().sum() > 0:
                    if fill_strategy == "Ù…ØªÙˆØ³Ø·":
                        df_clean[col].fillna(df_clean[col].mean(), inplace=True)
                    elif fill_strategy == "ÙˆØ³ÙŠØ·":
                        df_clean[col].fillna(df_clean[col].median(), inplace=True)
                    else:
                        df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)
        
        # Duplicates
        if drop_duplicates:
            initial_rows = len(df_clean)
            df_clean = df_clean.drop_duplicates()
            st.success(f"Ø­ÙØ°ÙØª {initial_rows - len(df_clean):,} ØµÙÙˆÙ Ù…ÙƒØ±Ø±Ø©")
        
        # Outliers (simplified IQR)
        if outlier_method == "IQR":
            for col in numeric_cols:
                Q1 = df_clean[col].quantile(0.25)
                Q3 = df_clean[col].quantile(0.75)
                IQR = Q3 - Q1
                lower = Q1 - 1.5 * IQR
                upper = Q3 + 1.5 * IQR
                df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]
        
        st.session_state.clean_df = df_clean
        st.session_state.progress.progress(50)
        return df_clean
    
    def eda_pro(self, df):
        """Professional EDA with multiple visualizations"""
        st.markdown("### ğŸ“Š Ø§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª (EDA)")
        
        col1, col2 = st.columns(2)
        with col1:
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            if numeric_cols:
                col_selected = st.selectbox("Ø§Ø®ØªØ± Ø¹Ù…ÙˆØ¯ Ø±Ù‚Ù…ÙŠ", numeric_cols)
                fig_hist = px.histogram(df, x=col_selected, 
                                      title=f"ØªÙˆØ²ÙŠØ¹ {col_selected}",
                                      marginal="box")
                st.plotly_chart(fig_hist, use_container_width=True)
        
        with col2:
            if len(numeric_cols) >= 2:
                col1_sel = st.selectbox("Ø§Ù„Ù…Ø­ÙˆØ± X", numeric_cols, index=0)
                col2_sel = st.selectbox("Ø§Ù„Ù…Ø­ÙˆØ± Y", numeric_cols, index=1)
                fig_scatter = px.scatter(df, x=col1_sel, y=col2_sel,
                                       title=f"Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† {col1_sel} Ùˆ {col2_sel}")
                st.plotly_chart(fig_scatter, use_container_width=True)
        
        # Correlation heatmap
        if len(numeric_cols) >= 2:
            st.subheader("ğŸ”¥ Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª")
            corr = df[numeric_cols].corr()
            fig_heatmap = px.imshow(corr, aspect="auto", color_continuous_scale="RdBu_r")
            st.plotly_chart(fig_heatmap, use_container_width=True)
        
        # Auto EDA Report
        if st.button("âš¡ ØªÙ‚Ø±ÙŠØ± EDA ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø´Ø§Ù…Ù„", type="primary"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø¯Ù‚ÙŠÙ‚Ø©"):
                profile = ProfileReport(df, title="ØªÙ‚Ø±ÙŠØ± DataWizard Pro", 
                                      explorative=True, minimal=False)
                st_profile_report(profile)
    
    def ml_pro(self, df):
        """Professional AutoML with PyCaret"""
        st.markdown("### ğŸ¤– AutoML Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ø¹ PyCaret")
        
        target_col = st.selectbox("ğŸ¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù", df.columns)
        task_type = st.radio("Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©", ["ØªØµÙ†ÙŠÙ", "ØªÙ†Ø¨Ø¤"])
        
        if st.button("ğŸš€ Ø¨Ø¯Ø¡ AutoML!", type="primary"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ¯Ø±ÙŠØ¨ 15+ Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹..."):
                temp_df = df.copy()
                
                # Prepare data
                X = temp_df.drop(columns=[target_col])
                y = temp_df[target_col]
                
                # Handle categorical variables
                categorical_cols = X.select_dtypes(include=['object']).columns
                for col in categorical_cols:
                    le = LabelEncoder()
                    X[col] = le.fit_transform(X[col].astype(str))
                
                # PyCaret setup
                if task_type == "ØªØµÙ†ÙŠÙ":
                    setup_df = pd.concat([X, y], axis=1)
                    setup_df.columns = [f"feature_{i}" if i != target_col else "target" 
                                      for i in range(len(setup_df.columns))]
                    s = setup(setup_df, target='target', session_id=123, silent=True)
                else:
                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                    s = setup(X_train, target=y_train, session_id=123, silent=True)
                
                # Compare models
                best_model = compare_models(n_select=5)
                tuned_model = tune_model(best_model)
                final_model = finalize_model(tuned_model)
                
                st.session_state.models['best'] = final_model
                st.success("âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø£ÙØ¶Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹!")
                
                # Show results
                st.subheader("ğŸ† Ù†ØªØ§Ø¦Ø¬ Ø£ÙØ¶Ù„ 5 Ù†Ù…Ø§Ø°Ø¬")
                models = pull()
                st.dataframe(models.head())
    
    def download_utils(self, df, filename="datawizard_results"):
        """Professional download utilities"""
        csv = df.to_csv(index=False)
        b64 = base64.b64encode(csv.encode()).decode()
        href = f'<a href="data:file/csv;base64,{b64}" download="{filename}.csv" class="success-box">ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸ÙŠÙØ©</a>'
        st.markdown(href, unsafe_allow_html=True)

# Main App
@st.cache_data
def main():
    app = DataWizardPro()
    
    # Step 1: Load Data
    if app.load_data():
        df_raw = st.session_state.df
        
        # Step 2: Auto Clean
        st.session_state.progress.progress(30)
        clean_df = app.auto_clean(df_raw)
        
        # Step 3: Tabs for Professional Analysis
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š Ø§Ø³ØªÙƒØ´Ø§Ù", "ğŸ” ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…", "ğŸ¤– AutoML", "ğŸ“ˆ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…"])
        
        with tab1:
            app.eda_pro(clean_df)
        
        with tab2:
            app.ml_pro(clean_df)
        
        with tab3:
            st.subheader("ğŸ›ï¸ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠØ©")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ", f"{len(clean_df):,}")
            with col2:
                st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©", f"{len(clean_df.columns)}")
            with col3:
                missing_pct = clean_df.isnull().sum().sum() / (len(clean_df) * len(clean_df.columns)) * 100
                st.metric("Ù†Ø³Ø¨Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©", f"{missing_pct:.1f}%")
            with col4:
                st.metric("Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©", f"{clean_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
        
        with tab4:
            app.download_utils(clean_df)
        
        st.balloons()
        st.session_state.progress.progress(100)
    else:
        st.info("ğŸ“¤ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„")

if __name__ == "__main__":
    main()
